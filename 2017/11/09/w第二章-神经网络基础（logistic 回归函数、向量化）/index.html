<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="机器学习,神经网络,深度学习," />










<meta name="description" content="2.1 二分分类 计算机保存一张图片，要保存三个独立矩阵，分别对应红、绿、蓝三个颜色通道举例：图为一张猫图，像素为 64x64， 就有三个 64x64 的矩阵 用特征向量 x 来表示图片则图片的维度n = nx = 64  64  3 = 12 288 在二分类问题中，目标是训练出一个分类器（x 作为输入，预测输出的结">
<meta name="keywords" content="机器学习,神经网络,深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="第二章-神经网络基础（logistic 回归函数、向量化）">
<meta property="og:url" content="http://yoursite.com/2017/11/09/w第二章-神经网络基础（logistic 回归函数、向量化）/index.html">
<meta property="og:site_name" content="LEMON的博客">
<meta property="og:description" content="2.1 二分分类 计算机保存一张图片，要保存三个独立矩阵，分别对应红、绿、蓝三个颜色通道举例：图为一张猫图，像素为 64x64， 就有三个 64x64 的矩阵 用特征向量 x 来表示图片则图片的维度n = nx = 64  64  3 = 12 288 在二分类问题中，目标是训练出一个分类器（x 作为输入，预测输出的结果标签为 y） 上图表现的是x是nx维的特征向量 训练集由m个训练样本构成 X矩">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/8448458-d9544ba0627121c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/8448458-9d25ceb326c80a72.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/8448458-5c14e7234e115d0e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/8448458-4196ae38fef87a62.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/8448458-14e568c7fba033ec.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/8448458-0d1a10da192e86b1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/8448458-372eefe2663e11c7.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2017-12-20T15:43:45.475Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第二章-神经网络基础（logistic 回归函数、向量化）">
<meta name="twitter:description" content="2.1 二分分类 计算机保存一张图片，要保存三个独立矩阵，分别对应红、绿、蓝三个颜色通道举例：图为一张猫图，像素为 64x64， 就有三个 64x64 的矩阵 用特征向量 x 来表示图片则图片的维度n = nx = 64  64  3 = 12 288 在二分类问题中，目标是训练出一个分类器（x 作为输入，预测输出的结果标签为 y） 上图表现的是x是nx维的特征向量 训练集由m个训练样本构成 X矩">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/8448458-d9544ba0627121c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/11/09/w第二章-神经网络基础（logistic 回归函数、向量化）/"/>





  <title>第二章-神经网络基础（logistic 回归函数、向量化） | LEMON的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LEMON的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/09/w第二章-神经网络基础（logistic 回归函数、向量化）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第二章-神经网络基础（logistic 回归函数、向量化）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-09T15:12:21+08:00">
                2017-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习与神经网络-吴恩达/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习与神经网络(吴恩达)</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,253字
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="2-1-二分分类"><a href="#2-1-二分分类" class="headerlink" title="2.1 二分分类"></a>2.1 二分分类</h3><ul>
<li>计算机保存一张图片，要保存三个独立矩阵，分别对应红、绿、蓝三个颜色通道<br>举例：图为一张猫图，像素为 64x64， 就有三个 64x64 的矩阵<br><img src="http://upload-images.jianshu.io/upload_images/8448458-d9544ba0627121c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="course2-1.jpg"></li>
<li>用特征向量 x 来表示图片<br>则图片的维度n = nx = 64 <em> 64 </em> 3 = 12 288</li>
<li>在二分类问题中，目标是训练出一个分类器（x 作为输入，预测输出的结果标签为 y）<br><img src="http://upload-images.jianshu.io/upload_images/8448458-9d25ceb326c80a72.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="course2-2.jpg"></li>
<li>上图表现的是x是nx维的特征向量</li>
<li>训练集由m个训练样本构成</li>
<li>X矩阵式m列 高为nx （训练样本作为列向量堆叠）（约定格式）<br>注： 也有(训练样本作为行向量堆叠）的矩阵形式，但在神经网络中一般用约定格式<a id="more"></a>
</li>
</ul>
<h3 id="2-2-logistic-回归模型"><a href="#2-2-logistic-回归模型" class="headerlink" title="2.2 logistic 回归模型"></a>2.2 logistic 回归模型</h3><p><img src="http://upload-images.jianshu.io/upload_images/8448458-5c14e7234e115d0e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="course2-3.jpg"></p>
<ul>
<li>线性回归中可用 </li>
<li>y = w^t * x + b</li>
<li>缺点： y 应该介于0和1之间 </li>
<li>可用sigmoid(z)函数，也就是上图中的G(z)</li>
<li>对于参数 w 和 b ：</li>
<li>b 对应一个拦截器</li>
</ul>
<h3 id="2-3-logistic-回归损失函数（成本函数）"><a href="#2-3-logistic-回归损失函数（成本函数）" class="headerlink" title="2.3 logistic 回归损失函数（成本函数）"></a>2.3 logistic 回归损失函数（成本函数）</h3><ul>
<li>损失函数L(^y,y)： 在单个训练样本中定义的，衡量了在单个训练样本上的表现</li>
<li>成本函数(代价函数) J（w，b）：衡量了在==全部训练样本==上的表现（在logistic函数中寻找合适的 w 和 b 让 y-hat 尽可能的小）<br><img src="http://upload-images.jianshu.io/upload_images/8448458-4196ae38fef87a62.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="course2-4.jpg"></li>
</ul>
<h3 id="2-4-阶梯下降法"><a href="#2-4-阶梯下降法" class="headerlink" title="2.4 阶梯下降法"></a>2.4 阶梯下降法</h3><p><img src="http://upload-images.jianshu.io/upload_images/8448458-14e568c7fba033ec.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="course2-5.jpg"></p>
<ul>
<li>成本函数 J （w，b）是一个凸函数（选择该函数的原因）<br>阶梯下降法的做法是： 从初始点开始，朝最陡的下坡方向走一步</li>
</ul>
<h3 id="2-5-向量化"><a href="#2-5-向量化" class="headerlink" title="2.5 向量化"></a>2.5 向量化</h3><ul>
<li>注：当你想写循环时，可以先检查numpy中是否有类似的内置函数</li>
<li>==向量化速度比循环快300倍==（真是个神奇的东西）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line">a = np.random.rand(1000000)</span><br><span class="line">b = np.random.rand(1000000)</span><br><span class="line"></span><br><span class="line">tic = time.time()</span><br><span class="line">c = np.dot(a,b)</span><br><span class="line">toc = time.time()</span><br><span class="line"></span><br><span class="line">print(c)</span><br><span class="line">print(&quot;Vectorized version(向量化):&quot; + str(1000*(toc-tic))+&quot;ms&quot;)</span><br><span class="line"></span><br><span class="line">c = 0</span><br><span class="line">tic = time.time()</span><br><span class="line">for i in range(1000000):</span><br><span class="line">    c += a[i]*b[i]</span><br><span class="line">toc = time.time()</span><br><span class="line"></span><br><span class="line">print(c)</span><br><span class="line">print(&quot;For loop(循环):&quot; + str(1000*(toc-tic))+ &quot;ms&quot;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 输出</span><br><span class="line">249961.060873</span><br><span class="line">Vectorized version(向量化):2.0003318786621094ms</span><br><span class="line">249961.060873</span><br><span class="line">For loop(循环):779.0098190307617ms</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>np.dot(W,X)</strong>：<br>eg: 计算Z = W^T+ b,向量化可以直接计算w^T(表示W的转置)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z = np.dot(W.T,X)+b</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="2-6-高度向量化的、非常高效的逻辑回归的梯度下降算法"><a href="#2-6-高度向量化的、非常高效的逻辑回归的梯度下降算法" class="headerlink" title="2.6 高度向量化的、非常高效的逻辑回归的梯度下降算法"></a>2.6 高度向量化的、非常高效的逻辑回归的梯度下降算法</h3><p><img src="http://upload-images.jianshu.io/upload_images/8448458-0d1a10da192e86b1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="course2-6.jpg"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Z = wTX + b = np. dot(w. T, X)</span><br><span class="line">A = σ(Z)</span><br><span class="line">dZ = A -Y</span><br><span class="line">dw = 1/m ∗ X ∗ dz^T</span><br><span class="line">db = 1/m * np. sum(dZ)</span><br><span class="line">w = w - α * dw</span><br><span class="line">b = b - α * db</span><br></pre></td></tr></table></figure></p>
<ul>
<li>我们利用前五个公式完成了前向和后向传播，也实现了对所有训练样本进行预测和求<br>导</li>
<li>利用后两个公式，梯度下降更新参数。</li>
<li>我们的目的是不使用for循环，所以我们就通过一次迭代实现一次梯度下降，但如果你希望多次迭代进行梯度下降，那么仍然需要for循环，放在最外层。不过我们还是觉得一次迭代就进行一次梯度下降，避免使用任何循环比较<br>舒服一些。</li>
</ul>
<h3 id="2-7-python中的广播机制-Broadcasting-in-Python"><a href="#2-7-python中的广播机制-Broadcasting-in-Python" class="headerlink" title="2.7 python中的广播机制( Broadcasting in Python)"></a>2.7 python中的广播机制( Broadcasting in Python)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">A = np.array([[56.0, 0.0, 4.4, 68.0],</span><br><span class="line">              [1.2, 104.0, 52.0, 8.0],</span><br><span class="line">              [1.8, 135.0, 99.0, 0.9]])</span><br><span class="line">print(A)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[  56.     0.     4.4   68. ]</span><br><span class="line"> [   1.2  104.    52.     8. ]</span><br><span class="line"> [   1.8  135.    99.     0.9]]</span><br></pre></td></tr></table></figure>
<ul>
<li>axis=0 意思是、在竖直方向上求和</li>
<li>axis=1 是在水平方向上求和<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cal = A.sum(axis=0)</span><br><span class="line">print(cal)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[  59.   239.   155.4   76.9]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">percentage = 100*A/cal.reshape(1,4)</span><br><span class="line">print(percentage)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[ 94.91525424   0.           2.83140283  88.42652796]</span><br><span class="line"> [  2.03389831  43.51464435  33.46203346  10.40312094]</span><br><span class="line"> [  3.05084746  56.48535565  63.70656371   1.17035111]]</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>axis</strong> 用来指明将要进行的运算是沿着<br>哪个轴执行，在 numpy 中， 0 轴是垂直的，也就是列，而 1 轴是水平的，也就是行</li>
<li>A/cal.reshape(1,4)指令则调用了 numpy 中的<strong>广播机制</strong>。</li>
</ol>
<ul>
<li>这里使用3X4的矩阵<br>A 除以1X4 的矩阵 cal。技术上来讲，其实并不需要再将矩阵 cal reshape(重塑)成1X4 ，因<br>为矩阵 cal 本身已经是1X4 了。但是当我们写代码时不确定矩阵维度的时候，通常会对矩阵<br>进行重塑来确保得到我们想要的列向量或行向量。</li>
<li>重塑操作 reshape是一个常量时间的操作，<br>时间复杂度是 O(1)，它的调用代价极低。</li>
</ul>
<ol>
<li>numpy 广播机制</li>
</ol>
<ul>
<li>如果两个数组的后缘维度的轴长度相符或其中一方的轴长度为 1，则认为它们是广播兼容的。</li>
<li>广播机制与执行的运算种类无关</li>
<li>广播会在缺失维度和轴长度为 1 的维度上进行。<br>后缘维度的轴长度： A.shape[-1] 即矩阵维度元组中的最后一个位置的值<br><img src="http://upload-images.jianshu.io/upload_images/8448458-372eefe2663e11c7.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="course2-7.jpg"></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          
            <a href="/tags/神经网络/" rel="tag"><i class="fa fa-tag"></i> 神经网络</a>
          
            <a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/11/08/机器学习实战四（神经网络）/" rel="next" title="机器学习实战四（神经网络）">
                <i class="fa fa-chevron-left"></i> 机器学习实战四（神经网络）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/11/14/w章二习题（NumPy基础、广播和向量化）/" rel="prev" title="章二习题（NumPy基础、广播和向量化）">
                章二习题（NumPy基础、广播和向量化） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">LEMON</p>
              <p class="site-description motion-element" itemprop="description">记录生活点滴</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/ZHBIT92" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-globe"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="http://www.jianshu.com/u/6f9b905040b9" target="_blank" title="简书">
                    
                      <i class="fa fa-fw fa-globe"></i>简书</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-二分分类"><span class="nav-number">1.</span> <span class="nav-text">2.1 二分分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-logistic-回归模型"><span class="nav-number">2.</span> <span class="nav-text">2.2 logistic 回归模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-logistic-回归损失函数（成本函数）"><span class="nav-number">3.</span> <span class="nav-text">2.3 logistic 回归损失函数（成本函数）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-阶梯下降法"><span class="nav-number">4.</span> <span class="nav-text">2.4 阶梯下降法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-向量化"><span class="nav-number">5.</span> <span class="nav-text">2.5 向量化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-高度向量化的、非常高效的逻辑回归的梯度下降算法"><span class="nav-number">6.</span> <span class="nav-text">2.6 高度向量化的、非常高效的逻辑回归的梯度下降算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-python中的广播机制-Broadcasting-in-Python"><span class="nav-number">7.</span> <span class="nav-text">2.7 python中的广播机制( Broadcasting in Python)</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LEMON</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>次
</span>
</div>



  <span class="post-meta-divider">|</span>



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共21.6k字</span>
</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

  
<div id="hexo-helper-live2d">
  <canvas id="live2dcanvas" width="150" height="300"></canvas>
</div>
<style>
  #live2dcanvas{
    position: fixed;
    width: 150px;
    height: 300px;
    opacity:0.7;
    right: 0px;
    z-index: 999;
    pointer-events: none;
    bottom: -20px;
  }
</style>
<script type="text/javascript" src="/live2d/device.min.js"></script>
<script type="text/javascript">
const loadScript = function loadScript(c,b){var a=document.createElement("script");a.type="text/javascript";"undefined"!=typeof b&&(a.readyState?a.onreadystatechange=function(){if("loaded"==a.readyState||"complete"==a.readyState)a.onreadystatechange=null,b()}:a.onload=function(){b()});a.src=c;document.body.appendChild(a)};
(function(){
  if((typeof(device) != 'undefined') && (device.mobile())){
    document.getElementById("live2dcanvas").style.width = '75px';
    document.getElementById("live2dcanvas").style.height = '150px';
  }else
    if (typeof(device) === 'undefined') console.error('Cannot find current-device script.');
  loadScript("/live2d/script.js", function(){loadlive2d("live2dcanvas", "/live2d/assets/z16.model.json", 0.5);});
})();
</script>

</body>
</html>
