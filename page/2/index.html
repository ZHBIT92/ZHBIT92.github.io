<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="记录生活点滴">
<meta property="og:type" content="website">
<meta property="og:title" content="LEMON的博客">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="LEMON的博客">
<meta property="og:description" content="记录生活点滴">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LEMON的博客">
<meta name="twitter:description" content="记录生活点滴">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>LEMON的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LEMON的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/06/机器学习实战总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/06/机器学习实战总结/" itemprop="url">机器学习实战总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-06T14:54:21+08:00">
                2017-11-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><ol>
<li>学习路线</li>
</ol>
<ul>
<li><a href="http://blog.csdn.net/longxinchen_ml/article/details/50749614" target="_blank" rel="noopener">机器学习系列_机器学习路线图(附资料)</a></li>
<li><a href="http://blog.csdn.net/zhongwen7710/article/details/45331915" target="_blank" rel="noopener">【重磅干货整理】机器学习(Machine Learning)与深度学习(Deep Learning)资料汇总</a>：真的是超多干货</li>
</ul>
<h3 id="零-算法概念"><a href="#零-算法概念" class="headerlink" title="零.算法概念"></a>零.算法概念</h3><ol>
<li>监督学习：需要用已知结果的数据做训练</li>
<li>无监督学习：不需要已知标签</li>
<li>连续型数据和离散型数据</li>
</ol>
<h3 id="1-算法分类"><a href="#1-算法分类" class="headerlink" title="1.算法分类"></a>1.算法分类</h3><ol>
<li>监督学习的用途</li>
</ol>
<p>分类</p>
<ul>
<li>k-邻近算法</li>
<li>朴素贝叶斯算法</li>
<li>支持向量机</li>
<li>决策树</li>
</ul>
<p>回归</p>
<ul>
<li>线性回归</li>
<li>逻辑回归</li>
<li>局部加权线性回归</li>
<li>Ridge回归</li>
<li>Lasso 最小回归系数估计</li>
</ul>
<ol>
<li>无监督学习的用途</li>
</ol>
<ul>
<li>聚类和降维</li>
<li>K-均值</li>
<li>DBSCAN</li>
<li>最大期望算法</li>
<li>Parzcn窗设计</li>
</ul>
<ol>
<li>特殊算法</li>
</ol>
<ul>
<li>推荐算法</li>
</ul>
<ol>
<li>一些小方法（子算法）</li>
</ol>
<ul>
<li>梯度下降法：主要运用在线性回归，逻辑回归，神经网络，推荐算法中</li>
<li>牛顿法：主要运用在线性回归</li>
<li>BP算法：主要运用在神经网络</li>
<li>SMO算法：主要运用在SVM中</li>
</ul>
<h3 id="2-如何选择合适的算法"><a href="#2-如何选择合适的算法" class="headerlink" title="2.如何选择合适的算法"></a>2.如何选择合适的算法</h3><p><img src="http://upload-images.jianshu.io/upload_images/8448458-4c889862933a9a40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h4 id="必须要考虑下面两个问题"><a href="#必须要考虑下面两个问题" class="headerlink" title="必须要考虑下面两个问题"></a>必须要考虑下面两个问题</h4><ul>
<li><ol>
<li>使用算法的目的，想要算法完成何种任务</li>
</ol>
</li>
<li><ol>
<li>需要分析或收集的数据是什么<h4 id="基于目的考虑"><a href="#基于目的考虑" class="headerlink" title="基于目的考虑"></a>基于目的考虑</h4></li>
</ol>
</li>
<li>想要预测目标的值，则选择监督学习算法，然后进一步确认目标变量的类型</li>
<li><ul>
<li>离散型变量: 选择分类算法</li>
</ul>
</li>
<li><ul>
<li>连续型变量: 选择回归算法</li>
</ul>
</li>
<li>否则选择无监督学习算法，随后进一步分析是否需要将数据分离为离散的组</li>
<li><ul>
<li>不需要: 聚类算法</li>
</ul>
</li>
<li><ul>
<li>需要: 密度估计算法</li>
</ul>
</li>
</ul>
<h4 id="基于数据考虑"><a href="#基于数据考虑" class="headerlink" title="基于数据考虑"></a>基于数据考虑</h4><ul>
<li>特征值的类型</li>
<li>特征值是否缺失</li>
<li>数据是否存在异常值</li>
<li>特征发生的频率是否罕见</li>
</ul>
<h4 id="天下没有免费的午餐"><a href="#天下没有免费的午餐" class="headerlink" title="天下没有免费的午餐"></a>天下没有免费的午餐</h4><ul>
<li>没有哪个算法能在所有问题中都表现得最优秀，因此我们只能在一定程度上缩小算法的选择范围，尝试不同算法的执行效率，不断试错，优化算法。</li>
</ul>
<h3 id="3-基本算法优缺点"><a href="#3-基本算法优缺点" class="headerlink" title="3.基本算法优缺点"></a>3.基本算法优缺点</h3><table>
<thead>
<tr>
<th>算法</th>
<th>优点</th>
<th>缺点</th>
<th>数据类型</th>
<th>优化方法</th>
<th>应用领域</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td><strong>K-邻近算法</strong></td>
<td>精度高、对异常值不敏感、无数据输入假定</td>
<td>计算复杂度高、空间复杂度高，占用存储空间</td>
<td>数值型和标称型</td>
<td></td>
<td>文本分类、模式识别、聚类分析，多分类领域</td>
</tr>
<tr>
<td></td>
<td><strong>决策树算法</strong></td>
<td>1.能实现对未知数据进行高效分类 2.有较好的可读性和描述性，利于辅助人工分析 3.分类效率高，一次构建后可反复使用</td>
<td>1.难以处理连续的特征 2. 容易发生过拟合（随机森林可以很大程度上减少过拟合） 3.对于多分类问题，计算量和准确率都不理想</td>
<td>数值型和标称型</td>
<td>1、对决策树进行剪枝 2、使用基于决策树的combination算法来解决过拟合的问题</td>
<td>企业管理实践，企业投资决策，由于决策树很好的分析能力，在决策过程应用较多。</td>
</tr>
<tr>
<td></td>
<td><strong>朴素贝叶斯</strong></td>
<td>1.朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。 2.对小规模的数据表现很好，能个处理多分类任务，适合增量式训练； 3.对缺失数据不太敏感，算法也比较简单，常用于文本分类。</td>
<td>1.需要计算先验概率 2.分类决策存在错误率 3.对输入数据的表达形式很敏感</td>
<td>标称型数据</td>
<td></td>
<td>文本分类、欺诈检测中使用较多</td>
</tr>
<tr>
<td></td>
<td><strong>人工神经网络</strong></td>
<td>1、分类准确度高，学习能力极强。 2、对噪声数据鲁棒性和容错性较强。 3、有联想能力，能逼近任意非线性关系。</td>
<td>1、神经网络参数较多，权值和阈值  2、黑盒过程，不能观察中间结果 3、学习过程比较长，有可能陷入局部极小值。</td>
<td></td>
<td></td>
<td>应用与计算机视觉，自然语言处理，语音识别等领域并取得很好的效果</td>
</tr>
</tbody>
</table>
<h3 id="3-适用框架"><a href="#3-适用框架" class="headerlink" title="3.适用框架"></a>3.适用框架</h3><table>
<thead>
<tr>
<th>Input(x)</th>
<th>Output (y)</th>
<th>Application</th>
<th>框架</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Home features</td>
<td>Price</td>
<td>Real Estate</td>
<td>standard NN</td>
</tr>
<tr>
<td></td>
<td>Ad，usr info</td>
<td>click on ad?(0/1)</td>
<td>Online Advertising</td>
<td>standard NN</td>
</tr>
<tr>
<td></td>
<td>Image</td>
<td>Object(1,…,1000)（给照片打标签</td>
<td>Photo tagging</td>
<td>CNN</td>
</tr>
<tr>
<td></td>
<td>Audio</td>
<td>Text transcript（输出文本）</td>
<td>Speech recognition</td>
<td>RNN</td>
</tr>
<tr>
<td></td>
<td>English</td>
<td>Chinese</td>
<td>Machine translation</td>
<td>RNNs</td>
</tr>
<tr>
<td></td>
<td>Image,Radar info</td>
<td>Position of other cars</td>
<td>Autonomous driving</td>
<td>custom Hybrid</td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/05/机器学习实战-Py3.X错误合集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/05/机器学习实战-Py3.X错误合集/" itemprop="url">机器学习实战-Py3.X错误合集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-05T14:54:21+08:00">
                2017-11-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="零-常见"><a href="#零-常见" class="headerlink" title="零. 常见"></a>零. 常见</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: &apos;range&apos; object doesn&apos;t support item deletion</span><br></pre></td></tr></table></figure>
<ul>
<li>注：3.x中range()要改为list(rang())，因为python3中range不返回数组对象，而是返回range对象</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: &apos;dict&apos; object has no attribute &apos;iteritems&apos;</span><br></pre></td></tr></table></figure>
<ul>
<li>iteritems()要改为items()</li>
</ul>
<h2 id="二-kNN"><a href="#二-kNN" class="headerlink" title="二. kNN"></a>二. kNN</h2><ul>
<li><p>报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NameError: name &apos;reload&apos; is not defined</span><br></pre></td></tr></table></figure>
</li>
<li><p>在前面加入命令(个人推荐直接写在mian函数里面简单快捷)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from imp import reload</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="四-朴素贝叶斯"><a href="#四-朴素贝叶斯" class="headerlink" title="四. 朴素贝叶斯"></a>四. 朴素贝叶斯</h2><ul>
<li><p>报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeDecodeError: &apos;gbk&apos; codec can&apos;t decode byte 0xae in position 199: illegal multibyte sequence</span><br></pre></td></tr></table></figure>
</li>
<li><p>那是因为书上的下面这两行代码有点问题：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wordList = textParse(open(&apos;email/spam/%d.txt&apos; % i).read()</span><br><span class="line">wordList = textParse(open(&apos;email/ham/%d.txt&apos; % i).read()</span><br><span class="line">需要将上面的代码更为下面这两行：</span><br><span class="line">wordList = textParse(open(&apos;email/spam/%d.txt&apos; % i, &quot;rb&quot;).read().decode(&apos;GBK&apos;,&apos;ignore&apos;) )</span><br><span class="line">wordList = textParse(open(&apos;email/ham/%d.txt&apos; % i,  &quot;rb&quot;).read().decode(&apos;GBK&apos;,&apos;ignore&apos;) )</span><br><span class="line"></span><br><span class="line">因为有可能文件中存在类似“�”非法字符。</span><br></pre></td></tr></table></figure>
</li>
<li><p>报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: &apos;range&apos; object doesn&apos;t support item deletion</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: &apos;dict&apos; object has no attribute &apos;iteritems&apos;</span><br></pre></td></tr></table></figure>
<ul>
<li>参考常见错误</li>
</ul>
<h2 id="五-Logistic回归"><a href="#五-Logistic回归" class="headerlink" title="五. Logistic回归"></a>五. Logistic回归</h2><ul>
<li>报错：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: &apos;numpy.float64&apos; object cannot be interpreted as an integer</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>这里是因为numpy版本问题，更改版本解决<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U numpy==1.11.0</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: &apos;range&apos; object doesn&apos;t support item deletion</span><br></pre></td></tr></table></figure>
</li>
<li><p>参考常见错误</p>
</li>
<li><p>报错：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: &apos;numpy.ndarray&apos; object has no attribute &apos;getA&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>注释掉plotBestFit()的矩阵转为数组，因为在输入时已经转换为数组了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plotBestFit(weights)</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">    # 矩阵变为数组,使用gradAscent时加入</span><br><span class="line">    weights = wei.getA()</span><br><span class="line">&apos;&apos;&apos;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="参考来自"><a href="#参考来自" class="headerlink" title="参考来自"></a>参考来自</h3><p><a href="http://www.jianshu.com/p/9eea9af8529b" target="_blank" rel="noopener">机器学习实战Py3.x填坑记</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/04/机器学习实战三（朴素贝叶斯）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/04/机器学习实战三（朴素贝叶斯）/" itemprop="url">机器学习实战三（朴素贝叶斯）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-04T14:54:21+08:00">
                2017-11-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h3><h4 id="1-原理："><a href="#1-原理：" class="headerlink" title="1. 原理："></a>1. 原理：</h4><ul>
<li>工作机制：<h4 id="2-优缺点"><a href="#2-优缺点" class="headerlink" title="2. 优缺点"></a>2. 优缺点</h4></li>
<li>优点：在数据少的情况下有效，可以处理多类别问题</li>
<li>缺点：</li>
<li><ul>
<li>对于输入数据的准备方式较为敏感</li>
</ul>
</li>
<li>适用数据范围：标称型数据<h4 id="3-条件概论："><a href="#3-条件概论：" class="headerlink" title="3.条件概论："></a>3.条件概论：</h4></li>
<li>在B的条件下A出现的概率。<br>p(A|B)=p(AB)/p(B)</li>
<li>交换条件中的条件与结果：<br>p(B|A)=p(A|B)*p(B)/p(A)<h4 id="4-贝叶斯决策理论的核心思想："><a href="#4-贝叶斯决策理论的核心思想：" class="headerlink" title="4.贝叶斯决策理论的核心思想："></a>4.贝叶斯决策理论的核心思想：</h4></li>
<li>选择具有最高概论的决策<h4 id="5-朴素贝叶斯算法的两个假设："><a href="#5-朴素贝叶斯算法的两个假设：" class="headerlink" title="5.朴素贝叶斯算法的两个假设："></a>5.朴素贝叶斯算法的两个假设：</h4></li>
<li>(1)每个特征之间都是独立的，这就使得公式：</li>
<li>p((f1,f2,…fn)|c)=p(f1|c)p(f2|c)…p(fn|c)</li>
<li>(2)每个特征同等重要，我们拿文本分类做例子，把文档中的单词作为特征。这种假设使得我们在进行分类的过程中无需考虑单词出现的次数，只考虑单词出现与否。这也就贝叶斯算法的贝努利模型实现方式。</li>
<li>注：贝叶斯的另一种实现方式为多项式模型，在这种模型中则需要考虑单词的出现次数。<h3 id="二、算法流程"><a href="#二、算法流程" class="headerlink" title="二、算法流程"></a>二、算法流程</h3></li>
</ul>
<ol>
<li>收集数据：可用任何方法</li>
<li>准备数据：需要数值型或者布尔型数据</li>
<li>分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好</li>
<li>训练算法：计算不同的独立特征的条件概率</li>
<li>测试算法：计算错误率</li>
<li>使用算法：一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本。</li>
</ol>
<h3 id="三、算法实践"><a href="#三、算法实践" class="headerlink" title="三、算法实践"></a>三、算法实践</h3><h4 id="1-问题"><a href="#1-问题" class="headerlink" title="1.问题"></a>1.问题</h4><ul>
<li>对是否属于侮辱性文章进行分类<h4 id="2-准备数据：从文本中构建词向量"><a href="#2-准备数据：从文本中构建词向量" class="headerlink" title="2.准备数据：从文本中构建词向量"></a>2.准备数据：从文本中构建词向量</h4></li>
<li>准备数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 产生训练数据</span><br><span class="line">def loadDataSet():</span><br><span class="line">    # 该数据取自某狗狗论坛的留言版</span><br><span class="line">    postingList=[[&apos;my&apos;, &apos;dog&apos;, &apos;has&apos;, &apos;flea&apos;, &apos;problems&apos;, &apos;help&apos;, &apos;please&apos;],</span><br><span class="line">                 [&apos;maybe&apos;, &apos;not&apos;, &apos;take&apos;, &apos;him&apos;, &apos;to&apos;, &apos;dog&apos;, &apos;park&apos;, &apos;stupid&apos;],</span><br><span class="line">                 [&apos;my&apos;, &apos;dalmation&apos;, &apos;is&apos;, &apos;so&apos;, &apos;cute&apos;, &apos;I&apos;, &apos;love&apos;, &apos;him&apos;],</span><br><span class="line">                 [&apos;stop&apos;, &apos;posting&apos;, &apos;stupid&apos;, &apos;worthless&apos;, &apos;garbage&apos;],</span><br><span class="line">                 [&apos;mr&apos;, &apos;licks&apos;, &apos;ate&apos;, &apos;my&apos;, &apos;steak&apos;, &apos;how&apos;, &apos;to&apos;, &apos;stop&apos;, &apos;him&apos;],</span><br><span class="line">                 [&apos;quit&apos;, &apos;buying&apos;, &apos;worthless&apos;, &apos;dog&apos;, &apos;food&apos;, &apos;stupid&apos;]]</span><br><span class="line">    # 标注每条数据的分类，这里0表示正常言论，1表示侮辱性留言</span><br><span class="line">    classVec = [0, 1, 0, 1, 0, 1]</span><br><span class="line">    return postingList, classVec</span><br><span class="line"></span><br><span class="line"># 建立词汇表</span><br><span class="line">def createVocabList(dataSet):</span><br><span class="line">    # 首先建立一个空集</span><br><span class="line">    vocabSet = set([])</span><br><span class="line">    # 遍历数据集中的每条数据</span><br><span class="line">    for document in dataSet:</span><br><span class="line">        # 这条语句中首先统计了每条数据的词汇集，然后与总的词汇表求并集</span><br><span class="line">        vocabSet = vocabSet | set(document)</span><br><span class="line">    return list(vocabSet)</span><br><span class="line"></span><br><span class="line"># 按照词汇表解析输入</span><br><span class="line">def setOfWords2Vec(vocabList, inputSet):</span><br><span class="line">    # 创建一个跟词汇表（vocabList）等长的向量，并将其元素都设为0</span><br><span class="line">    returnVec = [0]*len(vocabList)</span><br><span class="line">    # 遍历输入，将含有词汇表单词的文档向量设为1</span><br><span class="line">    for word in inputSet:</span><br><span class="line">        if word in vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] = 1</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;the word:%s is not in my vocabulary!&quot; % word)</span><br><span class="line">    return returnVec</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">命令行</span><br><span class="line">&gt;&gt;&gt; import bayes</span><br><span class="line">&gt;&gt;&gt; listOPosts,listClasses = bayes.loadDataSet()</span><br><span class="line">&gt;&gt;&gt; myVocabList = bayes.createVocabList(listOPosts)</span><br><span class="line">&gt;&gt;&gt; myVocabList</span><br><span class="line">&gt;&gt;&gt; bayes.setOfWords2Vec(myVocabList,listOPosts[0])</span><br><span class="line">&gt;&gt;&gt; bayes.setOfWords2Vec(myVocabList,listOPosts[3])</span><br></pre></td></tr></table></figure>
<h4 id="3-训练算法：从词向量计算概率"><a href="#3-训练算法：从词向量计算概率" class="headerlink" title="3.训练算法：从词向量计算概率"></a>3.训练算法：从词向量计算概率</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 朴素贝叶斯分类器训练函数</span><br><span class="line"># 输入参数trainMatrix表示输入的文档矩阵，trainCategory表示每篇文档类别标签所构成的向量</span><br><span class="line">def trainNB0(trainMatrix,trainCategory):</span><br><span class="line">    # 留言数目</span><br><span class="line">    numTrainDocs=len(trainMatrix)</span><br><span class="line">    # 变换矩阵的列数目，即词汇表数目</span><br><span class="line">    numWords=len(trainMatrix[0])</span><br><span class="line">    # 侮辱性留言的概率</span><br><span class="line">    pAbusive=sum(trainCategory)/float(numTrainDocs)</span><br><span class="line">    # 将所有词的出现数初始化为1，将分母初始化为2，从而降低计算多个概率的乘积结果为零的影响</span><br><span class="line">    p0Num=ones(numWords)</span><br><span class="line">    p1Num=ones(numWords)</span><br><span class="line">    p0Denom=2.0</span><br><span class="line">    p1Denom=2.0</span><br><span class="line">    for i in range(numTrainDocs):</span><br><span class="line">        # 统计每类单词的数目，注意我们这里讨论的是一个二分问题</span><br><span class="line">        # 所以可以直接用一个if...else...即可，如果分类较多，则需要更改代码</span><br><span class="line">        if trainCategory[i] == 1:</span><br><span class="line">            p1Num += trainMatrix[i]</span><br><span class="line">            p1Denom += sum(trainMatrix[i])</span><br><span class="line">        else:</span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    # 对每个类别除以该类中的总词数</span><br><span class="line">    # 防止下溢出</span><br><span class="line">    p1Vec = log(p1Num/p1Denom)</span><br><span class="line">    p0Vec = log(p0Num/p0Denom)</span><br><span class="line">    # 函数返回两个概率向量，及一个概率</span><br><span class="line">    return p0Vec, p1Vec, pAbusive</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import bayes</span><br><span class="line">&gt;&gt;&gt; listOPosts,listClasses = bayes.loadDataSet()</span><br><span class="line"># 该语句从预先加载值中调入数据</span><br><span class="line">&gt;&gt;&gt; myVocabList = bayes.creatVocabList(listOPosts)</span><br><span class="line">&gt;&gt;&gt; trainMat=[]</span><br><span class="line">&gt;&gt;&gt; for postinDoc in listOPosts:</span><br><span class="line">...   trainMat.append(bayes.setOfWords2Vec(myVocabList,postinDoc))</span><br><span class="line">...</span><br><span class="line"># 下面给出属于侮辱性文章的概论以及两个类别的概论向量</span><br><span class="line">&gt;&gt;&gt; p0V,p1V,pAb=bayes.trainNB0(trainMat,listClasses)</span><br><span class="line">&gt;&gt;&gt; pAb</span><br><span class="line">&gt;&gt;&gt; p0V</span><br><span class="line">&gt;&gt;&gt; p1V</span><br></pre></td></tr></table></figure>
<h4 id="4-测试算法-朴素贝叶斯分类函数"><a href="#4-测试算法-朴素贝叶斯分类函数" class="headerlink" title="4.测试算法: 朴素贝叶斯分类函数"></a>4.测试算法: 朴素贝叶斯分类函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 朴素贝叶斯分类函数</span><br><span class="line">def classifyNB(vec2Classify, p0Vec, p1Vec, pClass):</span><br><span class="line">    p1 = sum(vec2Classify*p1Vec)+log(pClass)</span><br><span class="line">    p0 = sum(vec2Classify*p0Vec)+log(1-pClass)</span><br><span class="line">    if p1 &gt; p0:</span><br><span class="line">        return 1</span><br><span class="line">    else:</span><br><span class="line">        return 0</span><br></pre></td></tr></table></figure>
<ul>
<li>该函数是用来测试（封装了一些操作）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#内嵌测试函数</span><br><span class="line">def testingNB():</span><br><span class="line">    listOPosts, listClasses=loadDataSet()</span><br><span class="line">    myVocabList = createVocabList(listOPosts)</span><br><span class="line">    trainMat = []</span><br><span class="line">    for postinDoc in listOPosts:</span><br><span class="line">      trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    p0V, p1V, p1 = trainNB0(trainMat, listClasses)</span><br><span class="line">    testEntry = [&apos;love&apos;, &apos;my&apos;, &apos;dalmation&apos;]</span><br><span class="line">    thisDoc = setOfWords2Vec(myVocabList, testEntry)</span><br><span class="line">    print(testEntry, &quot;classified as:&quot;, classifyNB(thisDoc, p0V, p1V, p1))</span><br><span class="line">    testEntry = [&apos;garbage&apos;, &apos;stupid&apos;]</span><br><span class="line">    thisDoc = setOfWords2Vec(myVocabList, testEntry)</span><br><span class="line">    print(testEntry, &quot;classified as:&quot;, classifyNB(thisDoc, p0V, p1V, p1))</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">命令行</span><br><span class="line">import bayes</span><br><span class="line">&gt;&gt;&gt; bayes.testingNB()</span><br><span class="line">[&apos;love&apos;, &apos;my&apos;, &apos;dalmation&apos;] classified as: 0</span><br><span class="line">[&apos;garbage&apos;, &apos;stupid&apos;] classified as: 1</span><br></pre></td></tr></table></figure>
<h4 id="5-词袋模型的转换函数-准备数据中优化"><a href="#5-词袋模型的转换函数-准备数据中优化" class="headerlink" title="5.词袋模型的转换函数(准备数据中优化)"></a>5.词袋模型的转换函数(准备数据中优化)</h4><ul>
<li>之前的算法我们只考虑了单词出现与否，使用的是一种词集模型。</li>
<li>贝叶斯有两种实现方式，另一种多项式模型，需要考虑每个单词出现的次数，就是所谓的词袋模型。</li>
<li>为了适应这种词袋模型，我们需要对函数setOfWords2Vec作一下修改<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#词袋模型的转换函数  </span><br><span class="line">def bagOfWords2VecMN(vocabList,inputSet):  </span><br><span class="line">    returnVec=[0]*len(vocabList)  </span><br><span class="line">    #遍历输入  </span><br><span class="line">    for word in inputSet:  </span><br><span class="line">        if word in vocabList:  </span><br><span class="line">            #现在每遇到一个单词会增加词向量中的对应量</span><br><span class="line">            returnVec[vocabList.index(word)]+=1  </span><br><span class="line">        else:  </span><br><span class="line">            print &quot;the word:%s is not in my vocabulary!&quot; %word  </span><br><span class="line">    return returnVec</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="四、示例：使用朴素贝叶斯进行垃圾邮件过滤"><a href="#四、示例：使用朴素贝叶斯进行垃圾邮件过滤" class="headerlink" title="四、示例：使用朴素贝叶斯进行垃圾邮件过滤"></a>四、示例：使用朴素贝叶斯进行垃圾邮件过滤</h3><h4 id="1-准备数据，切分文本"><a href="#1-准备数据，切分文本" class="headerlink" title="1.准备数据，切分文本"></a>1.准备数据，切分文本</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 该函数将每个句子都解析成单词，并忽略空格，标点符号以及长度小于3的单词</span><br><span class="line">def textParse(bigString):</span><br><span class="line">    import re</span><br><span class="line">    listOfTokens = re.split(r&apos;\W*&apos;, bigString)</span><br><span class="line">    return [tok.lower() for tok in listOfTokens if len(tok) &gt; 2]</span><br></pre></td></tr></table></figure>
<h4 id="2-分类器"><a href="#2-分类器" class="headerlink" title="2.分类器"></a>2.分类器</h4><p><a href="http://www.jianshu.com/p/9eea9af8529b" target="_blank" rel="noopener">错误信息合集（参考）</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"># 检测垃圾邮件</span><br><span class="line">def spamTest():</span><br><span class="line">    # 存放输入数据</span><br><span class="line">    docList = []</span><br><span class="line">    #存放类别标签</span><br><span class="line">    classList = []</span><br><span class="line">    # 所有的文本</span><br><span class="line">    fullText = []</span><br><span class="line">    # 分别读取邮件内容</span><br><span class="line">    for i in range(1, 26):</span><br><span class="line">        wordList = textParse(open(&apos;email/spam/%d.txt&apos; % i, &quot;rb&quot;).read().decode(&apos;GBK&apos;,&apos;ignore&apos;) )</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(1)</span><br><span class="line">        wordList = textParse(open(&apos;email/ham/%d.txt&apos; % i,  &quot;rb&quot;).read().decode(&apos;GBK&apos;,&apos;ignore&apos;) )</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(0)</span><br><span class="line">    vocabList = createVocabList(docList)</span><br><span class="line">    # range(50)表示从0到50，不包括50</span><br><span class="line">    trainingSet = list(range(50))</span><br><span class="line">    # 测试集</span><br><span class="line">    testSet = []</span><br><span class="line">    # 随机抽取是个作为测试集</span><br><span class="line">    for i in range(10):</span><br><span class="line">        # 从50个数据集中随机选取十个作为测试集，并把其从训练集中删除</span><br><span class="line">        randIndex = int(random.uniform(0,len(trainingSet)))</span><br><span class="line">        testSet.append(trainingSet[randIndex])</span><br><span class="line">        del(trainingSet[randIndex])</span><br><span class="line">    trainMat = []</span><br><span class="line">    trainClasses = []</span><br><span class="line"></span><br><span class="line">    for docIndex in trainingSet:</span><br><span class="line">        trainMat.append(setOfWords2Vec(vocabList, docList[docIndex]))</span><br><span class="line">        trainClasses.append(classList[docIndex])</span><br><span class="line">    # 使用训练集得到概率向量</span><br><span class="line">    p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses))</span><br><span class="line"></span><br><span class="line">    # 测试分类器的错误率</span><br><span class="line">    errorCount = 0</span><br><span class="line">    for docIndex in testSet:</span><br><span class="line">        wordVector = setOfWords2Vec(vocabList, docList[docIndex])</span><br><span class="line">        if classifyNB(array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:</span><br><span class="line">            errorCount += 1</span><br><span class="line">            print(&quot;Classification error:&quot;)</span><br><span class="line">            print(docList[docIndex])</span><br><span class="line">    print(errorCount)</span><br><span class="line">    print(&quot;the error rate is:&quot;, float(errorCount)/len(testSet))</span><br></pre></td></tr></table></figure></p>
<p><a href="https://github.com/ZHBIT92/deep_learn/tree/master/Naive_Bayes" target="_blank" rel="noopener">github代码</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/03/Logistic回归和Sigmoid函数/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/03/Logistic回归和Sigmoid函数/" itemprop="url">Logistic回归和Sigmoid函数</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-03T12:33:21+08:00">
                2017-11-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习与神经网络-吴恩达/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习与神经网络(吴恩达)</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h3><h4 id="1-原理："><a href="#1-原理：" class="headerlink" title="1. 原理："></a>1. 原理：</h4><ul>
<li>工作机制：<h4 id="2-优缺点"><a href="#2-优缺点" class="headerlink" title="2. 优缺点"></a>2. 优缺点</h4></li>
<li>优点：计算代价不高，易于理解和实现</li>
<li>缺点：</li>
<li><ul>
<li>容易欠拟合，分类精度可能不高</li>
</ul>
</li>
<li>适用数据范围：数值型和标称型数据</li>
</ul>
<p><a href="http://www.jianshu.com/p/823b25e4fbdb" target="_blank" rel="noopener">理论</a></p>
<h3 id="二、算法流程"><a href="#二、算法流程" class="headerlink" title="二、算法流程"></a>二、算法流程</h3><ol>
<li>收集数据：anyway</li>
<li>准备数据：需要数值型(要进行距离计算)，结构化数据格式最佳</li>
<li>分析数据：anyway</li>
<li>训练算法：大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数</li>
<li>测试算法：一旦训练步骤完成，分类将会很快</li>
<li>使用算法：</li>
</ol>
<ul>
<li>步骤一：输入一些数据，并将其转换成对应的结构化数值；</li>
<li>步骤二：基于训练好的回归系数对数值进行简单的回归计算，判定它们属于哪个类别；随后在输出的类别上做一些其他的分析工作</li>
</ul>
<h3 id="三、算法实践"><a href="#三、算法实践" class="headerlink" title="三、算法实践"></a>三、算法实践</h3><p><a href="http://www.jianshu.com/p/d18e9ad21ce9" target="_blank" rel="noopener">错误合集</a></p>
<h4 id="1-问题"><a href="#1-问题" class="headerlink" title="1.问题"></a>1.问题</h4><ul>
<li>准备数据</li>
<li>打开文件并逐行读取<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def loadDataSet():</span><br><span class="line">    # 定义数据集和标签</span><br><span class="line">    dataMat = []</span><br><span class="line">    labelMat = []</span><br><span class="line">    # 读取文件</span><br><span class="line">    fr = open(&apos;testSet.txt&apos;)</span><br><span class="line">    for line in fr.readlines():</span><br><span class="line">        lineArr = line.strip().split()</span><br><span class="line">        # 初始化数据</span><br><span class="line">        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])</span><br><span class="line">        labelMat.append(int(lineArr[2]))</span><br><span class="line">    return dataMat, labelMat</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import logRegres</span><br><span class="line">&gt;&gt;&gt; dataArr,labelMat = logRegres.loadDataSet()</span><br><span class="line">&gt;&gt;&gt; logRegres.gradAscent(dataArr,labelMat)</span><br><span class="line">matrix([[ 4.12414349],</span><br><span class="line">        [ 0.48007329],</span><br><span class="line">        [-0.6168482 ]])</span><br></pre></td></tr></table></figure>
<ul>
<li>回归函数和梯度上升算法<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#回归函数</span><br><span class="line">def sigmoid(intX):</span><br><span class="line">    return 1.0/(1+exp(-intX))</span><br><span class="line"></span><br><span class="line"># 梯度上升算法</span><br><span class="line">def gradAscent(dataMatIn,classLabels):</span><br><span class="line">    # 转换为Numpy数据类型</span><br><span class="line">    dataMatrix = mat(dataMatIn)</span><br><span class="line">    labelMat = mat(classLabels).transpose()</span><br><span class="line">    # 矩阵大小</span><br><span class="line">    m, n = shape(dataMatrix)</span><br><span class="line">    # 步长</span><br><span class="line">    alpha = 0.001</span><br><span class="line">    # 迭代次数</span><br><span class="line">    maxCycles = 500</span><br><span class="line">    # 系数矩阵初始化为1</span><br><span class="line">    weights = ones((n, 1))</span><br><span class="line">    for k in range(maxCycles):</span><br><span class="line">        # 变量h是一个列向量，元素个数等于样本个数</span><br><span class="line">        h = sigmoid(dataMatrix*weights)</span><br><span class="line">        error = (labelMat-h)</span><br><span class="line">        weights = weights+alpha*dataMatrix.transpose()*error</span><br><span class="line">    return weights</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="2-分析数据"><a href="#2-分析数据" class="headerlink" title="2.分析数据"></a>2.分析数据</h4><ul>
<li>利用Matplotlib画图</li>
<li>画出数据集和Logistic最佳拟合直线<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 画出最佳拟合直线</span><br><span class="line">def plotBestFit(wei):</span><br><span class="line">    import matplotlib.pyplot as plt</span><br><span class="line">    # 矩阵变为数组</span><br><span class="line">    weights = wei.getA()</span><br><span class="line">    # 加载数据</span><br><span class="line">    dataMat, labelMat = loadDataSet()</span><br><span class="line">    # 转化为数组</span><br><span class="line">    dataArr = array(dataMat)</span><br><span class="line">    # 数据的列数目</span><br><span class="line">    n = shape(dataArr)[0]</span><br><span class="line">    # 用于存放类1的点</span><br><span class="line">    xcord1 = []</span><br><span class="line">    ycord1 = []</span><br><span class="line">    # 用于存放类2的点</span><br><span class="line">    xcord2 = []</span><br><span class="line">    ycord2 = []</span><br><span class="line">    # 遍历所有点</span><br><span class="line">    for i in range(n):</span><br><span class="line">        if(int(labelMat[i]) == 1):</span><br><span class="line">            xcord1.append(dataArr[i, 1])</span><br><span class="line">            ycord1.append(dataArr[i, 2])</span><br><span class="line">        else:</span><br><span class="line">            xcord2.append(dataArr[i, 1])</span><br><span class="line">            ycord2.append(dataArr[i, 2])</span><br><span class="line">    # 画出所有点的信息</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(111)</span><br><span class="line">    ax.scatter(xcord1, ycord1, s=30, c=&apos;red&apos;, marker=&apos;s&apos;)</span><br><span class="line">    ax.scatter(xcord2, ycord2, s=30, c=&apos;green&apos;)</span><br><span class="line">    x = arange(-3.0, 3.0, 0.1)</span><br><span class="line">    # 画出分类的边界，函数的系数由之前的梯度上升算法求得</span><br><span class="line">    y = (-weights[0]-weights[1]*x)/weights[2]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    plt.xlabel(&apos;X1&apos;)</span><br><span class="line">    plt.ylabel(&apos;X1&apos;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Logistic/pic1.PNG" alt=""></p>
<h4 id="3-训练算法"><a href="#3-训练算法" class="headerlink" title="3.训练算法"></a>3.训练算法</h4><h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul>
<li>对于以上的算法，每次更新回归系数我们都需要遍历整个数据集，如果数据量过大，数亿或者成千上万个特征，那么==计算复杂度==就太高。<h5 id="改进：每次仅用一个样本更改回归系数，这种方法就成为-随机梯度上升算法-。"><a href="#改进：每次仅用一个样本更改回归系数，这种方法就成为-随机梯度上升算法-。" class="headerlink" title="改进：每次仅用一个样本更改回归系数，这种方法就成为==随机梯度上升算法==。"></a>改进：每次仅用一个样本更改回归系数，这种方法就成为==随机梯度上升算法==。</h5></li>
<li>这种在样本到来时对分类器进行增量更新的方式可以称为在线学习算法。相应的，一次处理所有数据称为批处理。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 随机梯度上升算法</span><br><span class="line">def stocGradAscent0(dataMatrix,classLabels):</span><br><span class="line">    # 无矩阵转换过程</span><br><span class="line">    m, n = shape(dataMatrix)</span><br><span class="line">    alpha = 0.01</span><br><span class="line">    weights = ones(n)</span><br><span class="line">    for i in range(m):</span><br><span class="line">        # 变量h和误差error都是数值</span><br><span class="line">        h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">        error = (classLabels[i]-h)</span><br><span class="line">        weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">    return weights</span><br></pre></td></tr></table></figure>
<p><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Logistic/pic2.PNG" alt=""></p>
<h5 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h5><ul>
<li>从结果中可以看出分类效果并不是很好，这主要是和迭代的次数和步长有关系，我们进一步修改算法，让迭代步长随着迭代次数的增加逐渐变小。另外，我们可以随机选取样本更新系数。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def stocGradAscent1(dataMatrix, classLabels, numIter=150):</span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    weights = ones(n)   #initialize to all ones</span><br><span class="line">    for j in range(numIter):</span><br><span class="line">        dataIndex = list(range(m))</span><br><span class="line">        for i in range(m):</span><br><span class="line">            # alpha在每次迭代时不断减小，但不会减到0</span><br><span class="line">            alpha = 4/(1.0+j+i)+0.0001</span><br><span class="line">            # 随机选取更新</span><br><span class="line">            randIndex = int(random.uniform(0, len(dataIndex)))</span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex]*weights))</span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            # 删除，进行下一次迭代</span><br><span class="line">            del(dataIndex[randIndex])</span><br><span class="line">    return weights</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Logistic/pic3.png" alt=""></p>
<h3 id="四-示例：预测病马的死亡率"><a href="#四-示例：预测病马的死亡率" class="headerlink" title="四.示例：预测病马的死亡率"></a>四.示例：预测病马的死亡率</h3><h4 id="1-问题：数据缺失"><a href="#1-问题：数据缺失" class="headerlink" title="1.问题：数据缺失"></a>1.问题：数据缺失</h4><ul>
<li>解决办法：</li>
<li>1.用可用特征的均值来替代</li>
<li>2.用特殊值来替代，如-1</li>
<li>3.忽略有缺失值的样本</li>
<li>4.使用相识样本的均值来替代</li>
<li>5.使用另外的机器学习算法预测缺失值<h4 id="2-准备数据：处理数据的缺失值"><a href="#2-准备数据：处理数据的缺失值" class="headerlink" title="2.准备数据：处理数据的缺失值"></a>2.准备数据：处理数据的缺失值</h4></li>
<li>用实数0来替换所有的缺失值（==NumPy数据类型不允许包含缺失值==）</li>
<li>作者自己并没有给出具体的实现方法（待补充）</li>
</ul>
<h4 id="3-测试算法：用Logistic回归进行分类"><a href="#3-测试算法：用Logistic回归进行分类" class="headerlink" title="3.测试算法：用Logistic回归进行分类"></a>3.测试算法：用Logistic回归进行分类</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># 通过输入回归系数和特征向量来计算对应sigmoid的值</span><br><span class="line">def classifyVector(inX, weights):</span><br><span class="line">    prob = sigmoid(sum(inX*weights))</span><br><span class="line">    if prob &gt; 0.5:</span><br><span class="line">        return 1.0</span><br><span class="line">    else:</span><br><span class="line">        return 0.0</span><br><span class="line"></span><br><span class="line">def colicTest():</span><br><span class="line">    # 导入数据</span><br><span class="line">    frTrain = open(&apos;horseColicTraining.txt&apos;)</span><br><span class="line">    frTest = open(&apos;horseColicTest.txt&apos;)</span><br><span class="line">    trainingSet = []; trainingLabels = []</span><br><span class="line">    for line in frTrain.readlines():</span><br><span class="line">        currLine = line.strip().split(&apos;\t&apos;)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        for i in range(21):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        trainingSet.append(lineArr)</span><br><span class="line">        trainingLabels.append(float(currLine[21]))</span><br><span class="line">    # 导入数据完成后利用stocGradAscent1（）来计算回归系数向量</span><br><span class="line">    trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, 1000)</span><br><span class="line">    errorCount = 0</span><br><span class="line">    numTestVec = 0.0</span><br><span class="line">    # 导入测试集并计算分类错误率</span><br><span class="line">    for line in frTest.readlines():</span><br><span class="line">        numTestVec += 1.0</span><br><span class="line">        currLine = line.strip().split(&apos;\t&apos;)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        for i in range(21):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        if int(classifyVector(array(lineArr), trainWeights))!= int(currLine[21]):</span><br><span class="line">            errorCount += 1</span><br><span class="line">    errorRate = (float(errorCount)/numTestVec)</span><br><span class="line">    print(&quot;the error rate of this test is: %f&quot; % errorRate)</span><br><span class="line">    return errorRate</span><br><span class="line"></span><br><span class="line"># 调用colicTest()函数10次并求结果的平均值</span><br><span class="line">def multiTest():</span><br><span class="line">    numTests = 10</span><br><span class="line">    errorSum=0.0</span><br><span class="line">    for k in range(numTests):</span><br><span class="line">        errorSum += colicTest()</span><br><span class="line">    print(&quot;after %d iterations the average error rate is: %f&quot; % (numTests, errorSum/float(numTests)))</span><br></pre></td></tr></table></figure>
<ul>
<li>在有30%的数据缺失的情况下，得到平均错误率约为33%</li>
<li>通过调整colicTest()中的迭代次数和stocGradAscent1()中的步长，平均错误率可以降到20%左右</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/02/机器学习实战二（决策树）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/02/机器学习实战二（决策树）/" itemprop="url">机器学习实战二（决策树）</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-02T14:54:21+08:00">
                2017-11-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="一-决策树"><a href="#一-决策树" class="headerlink" title="一. 决策树"></a>一. 决策树</h4><ol>
<li>概念： 决策树学习是根据数据的属性采用树状结构建立的一种决策模型，可以用此模型解决分类和回归问题。常见的算法包括 CART(Classification And Regression Tree), ID3, C4.5等。</li>
<li>优缺点</li>
</ol>
<ul>
<li>优点</li>
<li><ul>
<li>易于理解和解释，甚至比线性回归更直观；</li>
</ul>
</li>
<li><ul>
<li>与人类做决策思考的思维习惯契合；</li>
</ul>
</li>
<li><ul>
<li>模型可以通过树的形式进行可视化展示；</li>
</ul>
</li>
<li><ul>
<li>可以直接处理非数值型数据，不需要进行哑变量的转化，甚至可以直接处理含缺失值的数据；</li>
</ul>
</li>
<li><p>缺点：</p>
</li>
<li><ul>
<li>对于有大量数值型输入和输出的问题，决策树未必是一个好的选择；</li>
</ul>
</li>
<li><ul>
<li>产生过拟合</li>
</ul>
</li>
<li><ul>
<li>特别是当数值型变量之间存在许多错综复杂的关系，如金融数据分析；</li>
</ul>
</li>
<li><ul>
<li>决定分类的因素取决于更多变量的复杂组合时；</li>
</ul>
</li>
<li><ul>
<li>模型不够稳健，某一个节点的小小变化可能导致整个树会有很大的不同。</li>
</ul>
</li>
</ul>
<h4 id="二-决策树算法"><a href="#二-决策树算法" class="headerlink" title="二. 决策树算法"></a>二. 决策树算法</h4><ol>
<li>概念：决策树算法主要是指决策树进行创建中进行树分裂(划分数据集)的时候选取最优特征的算法，他的主要目的就是要选取一个特征能够将分开的数据集尽量的规整，也就是尽可能的纯. 最大的原则就是: ==将无序的数据变得更加有序==</li>
<li>决策树学习算法主要由三部分构成:</li>
</ol>
<ul>
<li>特征选择</li>
<li>决策树生成</li>
<li>决策树的剪枝</li>
</ul>
<h4 id="三-特征选择"><a href="#三-特征选择" class="headerlink" title="三. 特征选择"></a>三. 特征选择</h4><ol>
<li>常用方法：</li>
</ol>
<ul>
<li>信息增益(information gain)</li>
<li>增益比率(gain ratio)</li>
<li>基尼不纯度(Gini impurity)</li>
</ul>
<ol>
<li>代码实现<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 为所有可能的分类创建字典</span><br><span class="line">def uniquecounts(rows):</span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    for row in rows:</span><br><span class="line">        # 计数结果在最后一列</span><br><span class="line">        r = row[len(row)-1]</span><br><span class="line">        if r not in results:results[r] = 0</span><br><span class="line">        results[r]+=1</span><br><span class="line">    return results # 返回一个字典</span><br><span class="line"></span><br><span class="line"># 熵</span><br><span class="line">def entropy(rows):</span><br><span class="line">    from math import log</span><br><span class="line">    log2 = lambda x:log(x)/log(2)</span><br><span class="line">    results = uniquecounts(rows)</span><br><span class="line">    # 开始计算熵的值</span><br><span class="line">    ent = 0.0</span><br><span class="line">    for r in results.keys():</span><br><span class="line">        p = float(results[r])/len(rows)</span><br><span class="line">        # 以2为底求对数</span><br><span class="line">        ent = ent - p*log2(p)</span><br><span class="line">    return ent</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="四-决策树的生成"><a href="#四-决策树的生成" class="headerlink" title="四. 决策树的生成"></a>四. 决策树的生成</h4><ol>
<li>经典的实现算法：</li>
</ol>
<ul>
<li>ID3算法</li>
<li>C4.5算法</li>
<li>CART算法</li>
</ul>
<ol>
<li>ID3的算法思想（依据信息增益进行特征选取和分裂）</li>
</ol>
<ul>
<li>从根节点开始，选择信息增益最大的特征作为结点的特征，并由该特征的不同取值构建子节点</li>
<li>对子节点递归地调用以上方法，构建决策树</li>
<li>直到所有特征的信息增益均很小或者没有特征可选时为止。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 算法框架如下</span><br><span class="line">class DecisionTree(object):</span><br><span class="line">    def fit(self, X, y):</span><br><span class="line">        # 依据输入样本生成决策树</span><br><span class="line">        self.root = self._build_tree(X, y)</span><br><span class="line"></span><br><span class="line">    def _build_tree(self, X, y, current_depth=0):</span><br><span class="line">        #1. 选取最佳分割特征，生成左右节点</span><br><span class="line">        #2. 针对左右节点递归生成子树</span><br><span class="line">      </span><br><span class="line">    def predict_value(self, x, tree=None):</span><br><span class="line">        # 将输入样本传入决策树中，自顶向下进行判定</span><br><span class="line">        # 到达叶子节点即为预测值</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol>
<li>C4.5算法</li>
</ol>
<ul>
<li>C4.5算法与ID3算法的区别主要在于它在生产决策树的过程中，使用==信息增益==比来进行特征选择。</li>
</ul>
<ol>
<li>CART算法</li>
</ol>
<ul>
<li>CART假设决策树是一个二叉树，它通过递归地二分每个特征，将特征空间划分为有限个单元，并在这些单元上确定预测的概率分布。</li>
<li>CART算法中，对于回归树，采用的是平方误差最小化准则；对于分类树，采用基尼指数最小化准则。</li>
<li>平方误差最小化</li>
<li>基尼指数</li>
</ul>
<h4 id="五-决策树的剪枝"><a href="#五-决策树的剪枝" class="headerlink" title="五. 决策树的剪枝"></a>五. 决策树的剪枝</h4><ol>
<li>过拟合问题的解决方法：</li>
</ol>
<ul>
<li>当熵减少的数量小于某一个阈值时，就停止分支的创建。这是一种贪心算法。（限制Gain的阈值）</li>
<li>先创建完整的决策树，然后再尝试消除多余的节点，也就是采用减枝的方法。</li>
</ul>
<h4 id="六-完整代码"><a href="#六-完整代码" class="headerlink" title="六. 完整代码"></a>六. 完整代码</h4><ol>
<li>完整代码</li>
</ol>
<ul>
<li><a href="https://github.com/ZHBIT92/deep_learn/blob/master/Decision%20tree/test.py" target="_blank" rel="noopener">github决策树代码实践</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/29/w第一章-深度学习概论/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/29/w第一章-深度学习概论/" itemprop="url">第一章-深度学习概论</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-29T15:09:21+08:00">
                2017-10-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习与神经网络-吴恩达/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习与神经网络(吴恩达)</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-2-什么是神经网络"><a href="#1-2-什么是神经网络" class="headerlink" title="1.2 什么是神经网络"></a>1.2 什么是神经网络</h3><ol>
<li>ReLU函数（修正线性单元）：“修正”指的是取不小于0的值<br>图右是单个神经元：输入面积-&gt;computer运算-&gt;输出价格<br><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Neural_networks/course1-1.jpg" alt=""></li>
<li>多个神经元叠加构成一个更大的神经网络<br><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Neural_networks/course1-2.jpg" alt=""></li>
<li>左边的是输入的特征（输入层-input layer）</li>
</ol>
<ul>
<li>中间的圆圈在神经网络中被称为“隐藏单元”（Hidden nuit）：每个的输入都来着四个特征，因此是让神经网络自己决定中间的数代表的含义（why，这里为什么要这么说？）<br><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Neural_networks/course1-3.jpg" alt=""><h3 id="1-3-用神经网络进行监督学习"><a href="#1-3-用神经网络进行监督学习" class="headerlink" title="1.3 用神经网络进行监督学习"></a>1.3 用神经网络进行监督学习</h3></li>
<li>神经网络架构</li>
<li>1.standard neural network architecture 通用标准的神经网络架构</li>
<li><ol>
<li>convolutional neural  network 卷积神经网络（CNN）<br><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Neural_networks/course1-4.jpg" alt=""><br><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Neural_networks/course1-5.jpg" alt=""></li>
</ol>
</li>
<li>数据<br>Structured Data ：结构化数据（数据库），意为着每个特征都有清晰的定义，如数据库表中值的定义<br>Unstructured  Data : 非结构化数据，图像、音频文本中的内容<br><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Neural_networks/course1-6.jpg" alt=""><h3 id="1-4为什么深度学习流行起来"><a href="#1-4为什么深度学习流行起来" class="headerlink" title="1.4为什么深度学习流行起来"></a>1.4为什么深度学习流行起来</h3>数据量的增加<br>硬件设备的提升<br>算法的不断改进创新<br>规模推动深度学习的发展（神经网络性能随规模、数据的增长不断增长）<br>x轴代表训练的规模 ，y轴代表表现<br>数据集不大时，效果取决于手工设计的组件<br>在图形左边时，各个算法的效率不是很明确<br>ex： 但在大数据方面，足够的M（训练集）的支持使神经网络的效率领先其他算法<br><img src="https://github.com/ZHBIT92/deep_learn/raw/master/pic/Neural_networks/course1-7.jpg" alt=""></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/29/机器学习实战一（K-邻近算法（KNN））/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LEMON">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LEMON的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/29/机器学习实战一（K-邻近算法（KNN））/" itemprop="url">机器学习实战一（K-邻近算法（KNN））</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-29T14:54:21+08:00">
                2017-10-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习实战/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习实战</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h3><h4 id="1-原理："><a href="#1-原理：" class="headerlink" title="1. 原理："></a>1. 原理：</h4><ul>
<li>工作机制：给定测试样本，基于某种距离度量找出训练集中的与其最靠近的k个训练样本，然后基于这k个“邻居”的信息来进行预测.</li>
<li>通常k是不大于20的整数<h4 id="2-优缺点"><a href="#2-优缺点" class="headerlink" title="2. 优缺点"></a>2. 优缺点</h4></li>
<li>优点：精度高、对异常值不敏感、无数据输入假定</li>
<li>缺点：</li>
<li><ul>
<li>计算复杂度高、空间复杂度高，占用存储空间</li>
</ul>
</li>
<li><ul>
<li>无法给出数据的内在含义</li>
</ul>
</li>
<li>适用数据范围：数值型和标称型<h4 id="3-懒惰算法："><a href="#3-懒惰算法：" class="headerlink" title="3. 懒惰算法："></a>3. 懒惰算法：</h4></li>
<li>此类学习技术在训练阶段仅仅把样本保存起来</li>
<li>==训练开支为零==，待收到测试样本后再进行处理<h3 id="二、算法流程"><a href="#二、算法流程" class="headerlink" title="二、算法流程"></a>二、算法流程</h3></li>
</ul>
<ol>
<li>收集数据</li>
<li>准备数据</li>
<li>分析数据</li>
<li>训练算法（不适合KNN算法，因为K是“懒惰算法”的著名代表）</li>
<li>测试算法</li>
<li>使用算法</li>
</ol>
<h3 id="三、算法框架"><a href="#三、算法框架" class="headerlink" title="三、算法框架"></a>三、算法框架</h3><h4 id="1-classify0-函数的4个输入参数："><a href="#1-classify0-函数的4个输入参数：" class="headerlink" title="1. classify0()函数的4个输入参数："></a>1. classify0()函数的4个输入参数：</h4><ul>
<li>inX：用于分类的输入向量</li>
<li>dataSet：用于输入的训练样本集</li>
<li>labels：标签向量</li>
<li>k：参数k用于选择最佳邻居的数目</li>
</ul>
<h4 id="2-使用欧氏距离公式"><a href="#2-使用欧氏距离公式" class="headerlink" title="2. 使用欧氏距离公式"></a>2. 使用欧氏距离公式</h4><ul>
<li>计算两个向量点xA和xB之间的距离</li>
<li>计算存在4个特征值的数据集的距离</li>
</ul>
<h4 id="3-在约会网站上使用算法"><a href="#3-在约会网站上使用算法" class="headerlink" title="3. 在约会网站上使用算法"></a>3. 在约会网站上使用算法</h4><ul>
<li>海伦用三个属性来测试自己对于约会对象的喜爱程度<br>每年的飞行里程数<br>玩视频游戏所耗时间百分比<br>每周消费的冰激凌公升数<br>她积攒了一些数据，该数据保存在datingTestSet.txt中，共1000行。 </li>
<li><p>准备数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def createDataSet():</span><br><span class="line">    group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]])</span><br><span class="line">    labels = [&apos;A&apos;, &apos;A&apos;, &apos;B&apos;, &apos;B&apos;]</span><br><span class="line">    return group, labels</span><br></pre></td></tr></table></figure>
</li>
<li><p>算法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def classify0(inX,dataSet,labels,k):</span><br><span class="line">        #训练数据集的行数</span><br><span class="line">        dataSetSize=dataSet.shape[0]</span><br><span class="line">        #计算距离</span><br><span class="line">        #这里要说一下tile()函数，以后我们还会多次用到它</span><br><span class="line">        #tile(A,B)表示对A重复B次，B可以是int型也可以是数组形式</span><br><span class="line">        #如果B是int，表示在行方向上重复A，B次，列方向默认为1</span><br><span class="line">        #如果B是数组形式，tile(A,(B1,B2))表示在行方向上重复B1次，列方向重复B2次</span><br><span class="line">        diffMat=tile(inX,(dataSetSize,1))-dataSet</span><br><span class="line">        print(diffMat)</span><br><span class="line">        sqDiffMat=diffMat**2</span><br><span class="line">        print(sqDiffMat)</span><br><span class="line">        sqDistances=sqDiffMat.sum(axis=1)</span><br><span class="line">        distances=sqDistances**0.5</span><br><span class="line">        #排序，这里argsort()返回的是数据从小到大的索引值,这里这就是第几行数据</span><br><span class="line">        sortedDisIndicies =distances.argsort()</span><br><span class="line">        print(sortedDisIndicies)</span><br><span class="line">        classCount=&#123;&#125;</span><br><span class="line">        #选取距离最小的k个点，并统计每个类别出现的频率</span><br><span class="line">        #这里用到了字典get(key,default=None)返回键值key对应的值；</span><br><span class="line">        #如果key没有在字典里，则返回default参数的值，默认为None</span><br><span class="line">        for i in range(k):</span><br><span class="line">                voteIlabel=labels[sortedDisIndicies[i]]</span><br><span class="line">                classCount[voteIlabel]=classCount.get(voteIlabel,0)+1;</span><br><span class="line">        #逆序排序，找出出现频率最多的类别</span><br><span class="line">        sortedClassCount=sorted(classCount.items(),</span><br><span class="line">                                key=operator.itemgetter(1),reverse=True)</span><br><span class="line">        print(sortedClassCount)</span><br><span class="line">        return sortedClassCount[0][0]</span><br></pre></td></tr></table></figure>
</li>
<li><p>py3.5中iteritems改为items（上倒数第4行）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#进入python界面： </span><br><span class="line">&gt;&gt;&gt;import kNN </span><br><span class="line">&gt;&gt;&gt;group,labels=kNN.createDataSet() </span><br><span class="line">&gt;&gt;&gt;kNN.classify0([0,0],group,labels,3)</span><br></pre></td></tr></table></figure>
</li>
<li><p>读取txt的数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def file2matrix(filename):</span><br><span class="line">        fr=open(filename)</span><br><span class="line">        #读取文件</span><br><span class="line">        arrayOLines=fr.readlines()</span><br><span class="line">        #文件行数</span><br><span class="line">        numberOfLines=len(arrayOLines)</span><br><span class="line">        #创建全0矩阵</span><br><span class="line">        returnMat=zeros((numberOfLines,3))</span><br><span class="line">        #标签向量</span><br><span class="line">        classLabelVector=[]</span><br><span class="line">        index=0</span><br><span class="line">        #遍历每一行，提取数据</span><br><span class="line">        for line in arrayOLines:</span><br><span class="line">                line=line.strip();</span><br><span class="line">                listFromLine=line.split(&apos;\t&apos;)</span><br><span class="line">                #前三列为属性信息</span><br><span class="line">                returnMat[index,:]=listFromLine[0:3]</span><br><span class="line">                #最后一列为标签信息</span><br><span class="line">                classLabelVector.append(int(listFromLine[-1]))</span><br><span class="line">                index +=1</span><br><span class="line">        return returnMat,classLabelVector</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 重新加载kNN，得倒解析数据 </span><br><span class="line">&gt;&gt;&gt;reload(kNN) </span><br><span class="line">&gt;&gt;&gt;datingDataMat,datingLabels=kNN.file2matrix(&apos;datingTestSet2.txt&apos;)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>使用Matplotlib 创建散点图</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 命令行中输入</span><br><span class="line">&gt;&gt;&gt;import matplotlib </span><br><span class="line">&gt;&gt;&gt;import matplotlib.pyplot as plt </span><br><span class="line">&gt;&gt;&gt;from numpy import array </span><br><span class="line">&gt;&gt;&gt;fig = plt.figure() </span><br><span class="line">&gt;&gt;&gt;ax=fig.add_subplot(111) </span><br><span class="line">&gt;&gt;&gt;ax.scatter(datingDataMat[:,1],datingDataMat[:,2],15.0*array(datingLabels),15.0*array(datingLabels))</span><br><span class="line">&gt;&gt;&gt;plt.show()</span><br></pre></td></tr></table></figure>
</li>
<li><p>利用github存储图片并以markdown的链接形式显示<br>[图片上传失败…(image-2b31b0-1512123353929)]</p>
</li>
</ul>
<h4 id="4-数据的归一化"><a href="#4-数据的归一化" class="headerlink" title="4. 数据的归一化"></a>4. 数据的归一化</h4><ul>
<li>由于每个属性的取值数量级相差过大，会造成每个属性的权重不同，这显然是海伦不希望的。所以我们还要写一个函数实现数据归一化，公式如下:</li>
<li>newValue=(oldValue-min)/(max-min) </li>
<li>这个公式可以将特征值转化为0~1之间的值。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#归一化特征值</span><br><span class="line">def autoNorm(dataSet):</span><br><span class="line">        #每列的最小值</span><br><span class="line">        minVals=dataSet.min(0)</span><br><span class="line">        #每列的最大值</span><br><span class="line">        maxVals=dataSet.max(0)</span><br><span class="line">        #最大值与最小值的差值</span><br><span class="line">        ranges=maxVals-minVals</span><br><span class="line">        normDataSet=zeros(shape(dataSet))</span><br><span class="line">        m=dataSet.shape[0]</span><br><span class="line">        #minVals是1*3的矩阵，使用tile函数复制成和dataSet同样大小的矩阵，方便计算</span><br><span class="line">        normDataSet=dataSet-tile(minVals,(m,1))</span><br><span class="line">        normDataSet=normDataSet/tile(ranges,(m,1))</span><br><span class="line">        return normDataSet,ranges,minVals</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;reload(kNN) </span><br><span class="line">&gt;&gt;&gt;normMat,ranges,minVals=kNN.autoNorm(datingDataMat)</span><br></pre></td></tr></table></figure>
<h4 id="5-原始分类器"><a href="#5-原始分类器" class="headerlink" title="5. 原始分类器"></a>5. 原始分类器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#原始测试分类器</span><br><span class="line">def datingClassTest():</span><br><span class="line">        hoRatio=0.10</span><br><span class="line">        datingDataMat,datingLabels=file2matrix(&apos;datingTestSet2.txt&apos;)</span><br><span class="line">        normMat,ranges,minVals=autoNorm(datingDataMat)</span><br><span class="line">        m=normMat.shape(0)</span><br><span class="line">        #10%的数据用于测试数据集</span><br><span class="line">        numTestVecs=int(m*hoRatio)</span><br><span class="line">        errorCount=0.0</span><br><span class="line">        for i in range(numTestVecs):</span><br><span class="line">                classifierResults=classify0(normMat[i,:],normMat[numTestVecs:m,:], datingLabels[numTestVecs:m],3)</span><br><span class="line">                print(&quot;the classifier came back with: %d,the real answer id: %d&quot;%(classifierResults,datingLabels[i]))</span><br><span class="line">                if(classifierResults!=datingLabels[i]):errorCount +=1.0</span><br><span class="line">        print(&quot;the total error rate is: %f&quot; %(errorCount/float(numTestVecs)))</span><br></pre></td></tr></table></figure>
<h4 id="6-接口"><a href="#6-接口" class="headerlink" title="6. 接口"></a>6. 接口</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 约会网站预测函数</span><br><span class="line">def classifyPerson():</span><br><span class="line">        resultList=[&apos;not at all&apos;,&apos;in small doses&apos;,&apos;in large doses&apos;]</span><br><span class="line">        percentTats=float(input(&quot;在游戏上花费的时间占比( )?&quot;))</span><br><span class="line">        ffMiles=float(input(&quot;每年航空的里程数?&quot;))</span><br><span class="line">        iceCream=float(input(&quot;每年吃的冰淇淋（升）?&quot;))</span><br><span class="line">        datingDataMat,datingLabels=file2matrix(&apos;datingTestSet2.txt&apos;)</span><br><span class="line">        normMat, ranges, minVals=autoNorm(datingDataMat)</span><br><span class="line">        inArr=array([ffMiles,percentTats,iceCream])</span><br><span class="line">        classifierResult=classify0((inArr-minVals)/ranges,normMat,datingLabels,3)</span><br><span class="line">        print(&quot;你可能是属于以下这类人：&quot;,resultList[classifierResult - 1])</span><br></pre></td></tr></table></figure>
<p>[图片上传失败…(image-77db49-1512123353929)]<br>[图片上传失败…(image-dd2d24-1512123353929)]</p>
<h4 id="7-识别手写数字"><a href="#7-识别手写数字" class="headerlink" title="7. 识别手写数字"></a>7. 识别手写数字</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 将图片格式处理为一个向量（把一个32*32的二进制图形矩阵转换为1*1024的向量）,然后使用分类器处理图形信息</span><br><span class="line">def img2vector(filename):</span><br><span class="line">    # 创建一个1*1024的NumPy数组</span><br><span class="line">    returnVect = zeros((1,1024))</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    # 循环读出文件的前32行，并将每行的头32个字符值存储在NumPy数组中，最后返回数组</span><br><span class="line">    for i in range(32):</span><br><span class="line">        lineStr = fr.readline()</span><br><span class="line">        for j in range(32):</span><br><span class="line">            returnVect[0,32*i+j] = int(lineStr[j])</span><br><span class="line">    return returnVect</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">def handwritingClassTest():</span><br><span class="line">    hwLabels = []</span><br><span class="line">    # 将trainingDigits目录中的文件存储在列表中</span><br><span class="line">    trainingFileList = listdir(&apos;trainingDigits&apos;)</span><br><span class="line">    # 获得文件数赋值给m</span><br><span class="line">    m = len(trainingFileList)</span><br><span class="line">    # 创建一个m行1024列的训练矩阵，每行数据存储一个图像</span><br><span class="line">    trainingMat = zeros((m,1024))</span><br><span class="line">    for i in range(m):</span><br><span class="line">        # 从文件名解析分类数字（eg：文件9_45.txt表示数字9的第45个实例）</span><br><span class="line">        fileNameStr = trainingFileList[i]</span><br><span class="line">        fileStr = fileNameStr.split(&apos;.&apos;)[0]     #take off .txt</span><br><span class="line">        classNumStr = int(fileStr.split(&apos;_&apos;)[0])</span><br><span class="line">        # 将类代码存储在 hwLabels向量中</span><br><span class="line">        hwLabels.append(classNumStr)</span><br><span class="line">        # 使用 img2vector函数载入图像</span><br><span class="line">        trainingMat[i,:] = img2vector(&apos;trainingDigits/%s&apos; % fileNameStr)</span><br><span class="line"></span><br><span class="line">    # 将testDigits目录中的文件存储在列表中，步骤同上</span><br><span class="line">    testFileList = listdir(&apos;testDigits&apos;)        #iterate through the test set</span><br><span class="line">    errorCount = 0.0</span><br><span class="line">    mTest = len(testFileList)</span><br><span class="line">    for i in range(mTest):</span><br><span class="line">        fileNameStr = testFileList[i]</span><br><span class="line">        fileStr = fileNameStr.split(&apos;.&apos;)[0]     #take off .txt</span><br><span class="line">        classNumStr = int(fileStr.split(&apos;_&apos;)[0])</span><br><span class="line">        vectorUnderTest = img2vector(&apos;testDigits/%s&apos; % fileNameStr)</span><br><span class="line">        # 不同的是要使用 classify0函数测试目录下的每个文件（文件中的值介于0-1之间，无需用autoNorm()函数</span><br><span class="line">        classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)</span><br><span class="line">        print(&quot;the classifier came back with: %d, the real answer is: %d&quot; % (classifierResult, classNumStr))</span><br><span class="line">        if (classifierResult != classNumStr): errorCount += 1.0</span><br><span class="line">    print(&quot;\nthe total number of errors is: %d&quot; % errorCount)</span><br><span class="line">    print(&quot;\nthe total error rate is: %f&quot; % (errorCount/float(mTest)))</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/ZHBIT92/deep_learn/tree/master/KNN" target="_blank" rel="noopener">github代码</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">LEMON</p>
              <p class="site-description motion-element" itemprop="description">记录生活点滴</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/ZHBIT92" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-globe"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="http://www.jianshu.com/u/6f9b905040b9" target="_blank" title="简书">
                    
                      <i class="fa fa-fw fa-globe"></i>简书</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LEMON</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>次
</span>
</div>



  <span class="post-meta-divider">|</span>



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共字</span>
</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

  
<div id="hexo-helper-live2d">
  <canvas id="live2dcanvas" width="150" height="300"></canvas>
</div>
<style>
  #live2dcanvas{
    position: fixed;
    width: 150px;
    height: 300px;
    opacity:0.7;
    right: 0px;
    z-index: 999;
    pointer-events: none;
    bottom: -20px;
  }
</style>
<script type="text/javascript" src="/live2d/device.min.js"></script>
<script type="text/javascript">
const loadScript = function loadScript(c,b){var a=document.createElement("script");a.type="text/javascript";"undefined"!=typeof b&&(a.readyState?a.onreadystatechange=function(){if("loaded"==a.readyState||"complete"==a.readyState)a.onreadystatechange=null,b()}:a.onload=function(){b()});a.src=c;document.body.appendChild(a)};
(function(){
  if((typeof(device) != 'undefined') && (device.mobile())){
    document.getElementById("live2dcanvas").style.width = '75px';
    document.getElementById("live2dcanvas").style.height = '150px';
  }else
    if (typeof(device) === 'undefined') console.error('Cannot find current-device script.');
  loadScript("/live2d/script.js", function(){loadlive2d("live2dcanvas", "/live2d/assets/z16.model.json", 0.5);});
})();
</script>

</body>
</html>
